{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **DO NOT EDIT IF INSIDE annadl_f19 folder**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5: Recurrent neural networks\n",
    "\n",
    "Text, speech, weather, sensor output and video are but a few examples of the many types of data that is inherently sequential. So how does one predict the next word in a sentence, future temperatures or missing video frames? Using **recurrent neural networks** (RNNs)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T18:33:15.670464Z",
     "start_time": "2019-10-14T18:33:15.662510Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "from bs4 import BeautifulSoup\n",
    "import requests as rq\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text prediction is a good place to start when learning about RNNs, because most of us humans have a pretty well\n",
    "optimized inner model for text prediction ourselves. We can, therefore, easily assess the performance of a neural\n",
    "network in executing this task.\n",
    "\n",
    "Below is some code that loads the screenplay for Tarantino's 1994 film 'Pulp Fiction'. I recommend reading through the\n",
    "first 20 lines or so to get a feeling for the language and style used (and enjoy probably the best written screenplay\n",
    "in the history of film)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T18:32:13.444095Z",
     "start_time": "2019-10-14T18:32:11.758979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"PULP FICTION\" -- by Quentin Tarantino & Roger Avary\n",
      "\n",
      "\r\n",
      "                                      \"PULP FICTION\"\r\n",
      "\r\n",
      "                                            By\r\n",
      "\r\n",
      "                             Quentin Tarantino & Roger Avary\r\n",
      "\r\n",
      "                \r\n",
      "\r\n",
      "               PULP [pulp] n.\r\n",
      "\r\n",
      "               1. A soft, moist, shapeless mass or matter.\r\n",
      "\r\n",
      "               2. A magazine or book containing lurid subject matter and \r\n",
      "               being characteristically printed on rough, unfinished paper.\r\n",
      "\r\n",
      "               American Heritage Dictionary: New College Edition\r\n",
      "\r\n",
      "               INT. COFFEE SHOP – MORNING\r\n",
      "\r\n",
      "               A normal Denny's, Spires-like coffee shop in Los Angeles. \r\n",
      "               It's about 9:00 in the morning. While the place isn't jammed, \r\n",
      "               there's a healthy number of people drinking coffee, munching \r\n",
      "               on bacon and eating eggs.\r\n",
      "\r\n",
      "               Two of these people are a YOUNG MAN and a YOUNG WOMAN. The \r\n",
      "               Young Man has a slight working-class English accent and, \r\n",
      "               like his fellow countryman, smokes cigarettes like they're \r\n",
      "               going out of style.\r\n",
      "\r\n",
      "               It is impossible to tell where the Young Woman is from or \r\n",
      "               how old she is; everything she does contradicts something \r\n",
      "               she did. The boy and girl sit in a booth. Their dialogue is \r\n",
      "               to be said in a rapid pace \"HIS GIRL FRIDAY\" fashion.\r\n",
      "\r\n",
      "                                     YOUNG MAN\r\n",
      "                         No, forget it, it's too risky. I'm \r\n",
      "                         through doin' that shit.\r\n",
      "\r\n",
      "                                     YOUNG WOMAN\r\n",
      "                         You always say that, the same thing \r\n",
      "                         every time: never again, I'm through, \r\n",
      "                         too dangerous.\r\n",
      "\r\n",
      "                                     YOUNG MAN\r\n",
      "                         I know that's what I always say. I'm \r\n",
      "                         always right too, but –\r\n",
      "\r\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "response = rq.get(\"http://www.dailyscript.com/scripts/pulp_fiction.html\")\n",
    "text = BeautifulSoup(response.content, \"html.parser\").getText()\n",
    "print(text[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.1.1:** What is the most used symbol in this screenplay and what accuracy would a model constantly predicting this symbol obtain? In other words, what is the \"baseline accuracy\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've adapted some code for text generation from [this Keras example](https://keras.io/examples/lstm_text_generation/).\n",
    "I've inserted some questions in the code (look for `Q:`) for you to answer in the exercise below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T21:10:08.952688Z",
     "start_time": "2019-10-14T21:09:02.996574Z"
    }
   },
   "outputs": [],
   "source": [
    "# Q1: What is the purpose of this block? When is `char_indices` used? What about `indices_char`?\n",
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# Q2: What is the purpose of this block? What does the `seqlen` and `step` parameters do?\n",
    "seqlen = 40\n",
    "step = seqlen\n",
    "sentences = []\n",
    "for i in range(0, len(text) - seqlen - 1, step):\n",
    "    sentences.append(text[i: i + seqlen + 1])\n",
    "\n",
    "# Q3: What about this block? What is `x` and what is `y`? Why do they have this dimensionality?\n",
    "x = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    # Q3a: What happens in this loop?\n",
    "    for t, (char_in, char_out) in enumerate(zip(sentence[:-1], sentence[1:])):\n",
    "        x[i, t, char_indices[char_in]] = 1\n",
    "        y[i, t, char_indices[char_out]] = 1\n",
    "\n",
    "\n",
    "# Q4: Here we build the model. What does the `return_sequences` argument do? Why the dense layer at the end?\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seqlen, len(chars)), return_sequences=True))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=RMSprop(learning_rate=0.01),\n",
    "    metrics=['categorical_crossentropy', 'accuracy']\n",
    ")\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"Helper function to sample an index from a probability array.\"\"\"\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.exp(np.log(preds) / temperature)  # softmax\n",
    "    preds = preds / np.sum(preds)                #\n",
    "    probas = np.random.multinomial(1, preds, 1)  # sample index\n",
    "    return np.argmax(probas)                     #\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    \"\"\"Function invoked at end of each epoch. Prints generated text.\"\"\"\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - seqlen - 1)\n",
    "    \n",
    "    # Q5: What does diversity do?\n",
    "    for diversity in [0.2, 0.5, 1.0]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + seqlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "            \n",
    "            # What is the dimensionality of `preds`? Why do we input `preds[0, -1]` to the `sample` function?\n",
    "            preds = model.predict(x_pred, verbose=0)\n",
    "            next_index = sample(preds[0, -1], diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.1.2**: Add a callback for Tensorboard, so you can log the training process. Start training the network (takes ~10 minutes on my computer). While it's running move on to the next question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.1.3**: Answer the questions in the code above (look for code comments starting with `Q:`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.1.4**: Did the network finish training? Consider the generated text across epochs.\n",
    "1. In the early batches (0-10), the generated text looks very bad. Can you explain why the low diversity generated text contains almost only the symbol \" \" (that is, spaces)?\n",
    "2. The high diversity generated text is messed up too, but in a different way. Explain how.\n",
    "3. In later batches (20-30) what do you notice is off about the low diversity generated text?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.1.5**: For the network trained over all 50 epochs, generate a longer piece of text\n",
    "(say 5000 symbols long). Use the sentence `text[1486:1526]` as seed (starts with 'YOUNG MAN' ends with 'No, ')\n",
    "and set diversity to 0.5.\n",
    "Describe what features of the screenplay and language in general that the network learned in only 50 epochs.\n",
    "Also describe what serious mistakes it makes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.1.6**: Do the same as above, but for 40 random letters (e.g. smash away on your keyboard) as seed. What happens? Can you explain why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Challenge** Download [this](https://www.yelp.com/dataset/download) Yelp dataset and train a model that predicts rating given a review text!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
